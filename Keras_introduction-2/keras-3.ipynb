{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22ddb4-b51c-4bc5-9657-3080c65c5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Biz bir onceki dosyada  temel aktivasyon fonksiyonlarını ele aldık. Aslında bir onceki dosyada ele aldığımızdan daha fazla \n",
    "aktivasyon fonksiyonu vardır. Şimdi de optimizasyon algoritmasının minimize etmeye çalıştığı \"loss\" fonksiyonları \n",
    "üzerinde duracağız. \n",
    "\n",
    "loss fonksiyonları gerçek değerlerle ağın tahmin ettiği değerleri girdi olarak alıp bu farklılığı bir sayısal sayısal değerle \n",
    "ifade eden fonksiyonlardır. Optimizasyon algoritmaları bu loss fonksiyonlarının değerini düşürmeye çalışmaktadır. Gerçek\n",
    "değerlerle ağın ürettiği değerlerin arasındaki farkın minimize edilmesi aslında ağın gerçek değerlere yakın değerler üretmesi\n",
    "anlamına gelmektedir. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402a18f-ff5b-4ce8-a19d-31147d5cdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Anımsanacağı gibi \"w\" ve \"bias\" değerleri \"optimizer\" denilen algoritma tarafından her batch işleminde güncellenmekteydi. \n",
    "Yukarıda da belirttiğimiz gibi optimizer algoritması aslında \"loss\" denilen bir fonksiyonu minimize etmeye çalışmaktadır. \n",
    "Başka bir deyişle \"loss\" fonksiyonu aslında \"w\" ve \"bias\" değerlerinin güncellenmesi için bir amaç fonksiyonu görevini \n",
    "görmektedir. Değişik problemler için değişik loss fonksiyonları bulunmaktadır. Programcı model sınıfının compile metodunda \n",
    "loss parametresiyle loss fonksiyonu isimsel biçimde girebilir. Ya da isterse tensorflow.keras.losses modülündeki sınıflar \n",
    "ve fonksiyonlar yoluyla girebilir. (Loss fonksiyonları için Tensorflow hem callable sınıflar hem de fonksiyonlar bulundurmuştur.)\n",
    "\n",
    "Eğitim batch batch yapıldığı için loss fonksiyonları tek bir satırın çıktısından değil n tane satırın çıktısından hesaplanmaktadır. \n",
    "Yani bir batch işleminin gerçek sonucu ile ağdan o batch için elde edilecek kestirim sonuçlarına dayanılarak loss değerleri \n",
    "hesaplanmaktadır. Örneğin batch_size = 32 olduğu durumda aslında Keras ağa 32'lik bir giriş uygulayıp 32'lik bir çıktı elde \n",
    "eder. Bu 32 çıktı değeri gerçek 32 değerle loss fonksiyonuna sokulur.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947091b5-8a53-4629-b230-452c00042c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regresyon problemleri için en yaygın kullanılan loss fonksiyonu \"Mean Squared Error (MSE)\" denilen fonksiyondur.  Bu fonksiyona \n",
    "Türkçe \"Ortalama Karesel Hata\" diyebiliriz.  MSE fonksiyonu çıktı olarak gerçek değerlerden kestirilen değerlerin farkının \n",
    "karelerinin ortalamasını vermektedr. Fonksiyonun sembolik gösterimi şöyledir:\n",
    "\n",
    "mse = np.mean((y - y_hat) ** 2)\n",
    "\n",
    "Burada y gerçek değerleri, y_hat ise kestirilen değerleri belirtmektedir. Örneğin:\n",
    "\n",
    ">>> y = np.array([1, 2, 3, 4, 5])\n",
    ">>> y_hat = np.array([1.1, 1.9, 3.2, 3.8, 5.02])\n",
    ">>> np.mean((y - y_hat) ** 2)\n",
    "0.020080000000000032\n",
    "\n",
    "Aynı işlemi tensorflow.keras.losses modülündeki mse (ya da mean_squared_error) fonksiyonuyla da aşağıdaki gibi yapabilirdik:\n",
    "\n",
    ">>> from tensorflow.keras.losses import mse\n",
    ">>> mse(y, y_hat)\n",
    "<tf.Tensor: shape=(), dtype=float64, numpy=0.020080000000000032>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d894fe-c3e8-4050-969d-a23384b727da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regresyon problemleri için kullanılabilen diğer bir loss fonksiyonu da \"Mean Absolute Error (MAE)\" isimli fonksiyondur. \n",
    "Bu fonksiyona da Türkçe \"Ortalama Mutlak Hata\" diyebiliriz. Ortalama mutlak hata gerçek değerlerden kestirilen değerlerin \n",
    "farklarının mutlak değerlerinin ortalaması biçiminde hesaplanmaktadır. Sembolik gösterimi şöyledir:\n",
    "\n",
    "mae = np.mean(np.abs(y - y_hat))\n",
    "\n",
    "Burada y gerçek değerleri y_hat ise ağın kestirdiği değerleri belirtmektedir. Regresyon problemleri için loss fonksiyonu \n",
    "olarak çoğu kez MSE tercih edilmektedir. Çünkü kare alma işlemi algoritmalar için daha uygun bir işlemdir. Aynı zamanda d\n",
    "eğerleri daha fazla farklılaştırmaktadır. MAE loss fonksiyonundan ziyade metrik değer olarak \"insan algısına \n",
    "\n",
    ">>> y = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    ">>> y_hat = np.array([1.1, 1.9, 3.2, 3.8, 5.02])\n",
    ">>> mae = np.mean(np.abs(y - y_hat))\n",
    ">>> mae\n",
    "0.12400000000000003\n",
    "\n",
    "Ortalama karesel hata bir metrik değer olarak bizim için iyi bir çağrışım yapmamaktadır. Halbuki ortalama mutlak hata\n",
    "bizim için anlamlı bir çağrışım yapmaktadır. Örneğin ağımızın ortalama mutlak hatası 0.124 ise gerçek değer ağımızın bulduğu \n",
    "değerden 0.124 solda ya da sağda olabilir. Yine ortalama mutlak hata tensorflow.keras.losses modülü içerisindeki \"mae\" ya da \n",
    "\"mean_absolute_error\" isimli fonksiyonla da hesaplanabilmektedir. Örneğin:\n",
    "\n",
    ">>> from tensorflow.keras.losses import mae\n",
    ">>> y = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    ">>> y_hat = np.array([1.1, 1.9, 3.2, 3.8, 5.02])\n",
    ">>> result = mae(y, y_hat)\n",
    ">>> result\n",
    "<tf.Tensor: shape=(), dtype=float64, numpy=0.12400000000000003>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44baf47-ee07-44b0-994c-ed70ef1b9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regresyon problemleri için diğer bir loss fonksiyonu da \"Mean Absolute Percentage Error (MAPE)\" isimli fonksiyondur. Fonkisyonun \n",
    "sembolik ifadesi şöyledir:\n",
    "\n",
    "mape = 100 * np.mean(np.abs(y - y_hat) / y)\n",
    "\n",
    "Burada y gerçek değerleri y_hat ise ağın kestirdiği değerleri belirtmektedir. Örneğin:\n",
    "\n",
    ">>> y = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    ">>> y_hat = np.array([1.1, 1.9, 3.2, 3.8, 5.02])\n",
    ">>> mape = 100 * np.mean(np.abs(y - y_hat) / y)\n",
    ">>> mape\n",
    "5.413333333333335\n",
    "\n",
    "Tabii aynı işlemi yine tensorflow.keras.losses modülündeki \"mape\" fonksiyonuyla da yapabiliriz:\n",
    "\n",
    ">>> from tensorflow.keras.losses import mape\n",
    ">>> y = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    ">>> y_hat = np.array([1.1, 1.9, 3.2, 3.8, 5.02])\n",
    ">>> result = mape(y, y_hat)\n",
    ">>> result\n",
    "<tf.Tensor: shape=(), dtype=float64, numpy=5.413333333333335>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cf00e-b48d-4da4-bd16-fb6b5d1bc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regresyon problemleri için diğer bir loss fonksiyonu da \"Mean Squared Logarithmic Error (MSLE)\" isimli fonksiyondur.  Bu \n",
    "fonksiyon gerçek değerlerle kestirilen değerlerin logaritmalarının farklarının karelerinin ortalaması biçiminde hesaplanır. \n",
    "Sembolik ifadesi şöyledir:\n",
    "\n",
    "msle = np.mean((np.log(y) - np.log(y_hat)) ** 2)\n",
    "\n",
    "Bazen bu fonksiyon gerçek ve kestirilen değerlere 1 toplanarak da oluşturulabilmektedir (Tensorflow \"msle\" fonksiyonunu \n",
    "bu biçimde kullanmaktadır):\n",
    "\n",
    "msle = np.mean((np.log(y + 1) - np.log(y_hat + 1)) ** 2)\n",
    "\n",
    "Örneğin:\n",
    "\n",
    ">>> y = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    ">>> y_hat = np.array([1.1, 1.9, 3.2, 3.8, 5.02])\n",
    ">>> msle = np.mean((np.log(y + 1) - np.log(y_hat + 1)) ** 2)\n",
    ">>> msle\n",
    "0.0015175569737783628\n",
    "\n",
    "Aynı işlemi tensorflow.keras.losses modülündeki \"msle\" fonksiyonuyla da yapabiliriz:\n",
    "\n",
    ">>> from tensorflow.keras.losses import msle\n",
    ">>> y = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    ">>> y_hat = np.array([1.1, 1.9, 3.2, 3.8, 5.02])\n",
    ">>> result = msle(y, y_hat)\n",
    ">>> result\n",
    "<tf.Tensor: shape=(), dtype=float64, numpy=0.0015175569737783555>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebff5f0-22f5-4b19-bb97-5562d201cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "İkili sınıflandırma problemleri için en yaygın kullanılan loss fonksiyonu \"Binary Cross-Entropy (BCE)\" denilen fonksiyondur. \n",
    "Bu fonksiyonun sembolik gösterimi şöyledir:\n",
    "\n",
    "bce = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "Burada bir toplam teriminin olduğunu görüyorsunuz. Gerçek değerler 0 ya da 1 olduğuna göre bu toplam teriminin ya sol tarafı \n",
    "ya da sağ tarafı 0 olacaktır.. Burada yapılmak istenen şey aslında isabet olasılığının logaritmalarının ortalamasının alınmasıdır. \n",
    "Örneğin gerçek y değeri 0 olsun ve ağ da sigmoid çıktısından 0.1 elde etmiş olsun. Bu durumda toplam fadesinin sol tarafı 0,\n",
    "sağ tarafı ise log(0.9) olacaktır. Şimdi gerçek değerin 1 ancak ağın sigmoid çıktısından elde edilen değerim 0.9 olduğunu \n",
    "düşününelim. Bu kez toplamın sağ tarafı 0, sol tarafı ise log(0.9) olacaktır. İşte fonksiyonda bu biçimde isabet olasılıklarının \n",
    "logaritmalarının ortalaması bulunmaktadır. Örneğin:\n",
    "\n",
    ">>> y = np.array([1, 0, 1, 1, 0])\n",
    ">>> y_hat = np.array([0.9, 0.05, 0.095, 0.89, 0.111])\n",
    ">>> -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "0.5489448114302314\n",
    "\n",
    "Aynı işlemi tensorflow.keras.losses modülündeki binary_crossentropy isimli fonksiyonla da yapabiliriz:\n",
    "\n",
    ">>> y_hat = np.array([0.9, 0.05, 0.095, 0.89, 0.111])\n",
    ">>> result = binary_crossentropy(y, y_hat)\n",
    ">>> result\n",
    "<tf.Tensor: shape=(), dtype=float64, numpy=0.5489445126600796>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec46d5-031f-41af-8f6f-bf9b2480e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cok sınıflı sınıflandırma problemleri için en yaygın kullanılan loss fonksiyonu ise \"Categorical Cross-Entropy (CCE)\" isimli \n",
    "fonksiyondur. CCE fonksiyonu aslında BCE fonksiyonun çoklu biçimidir. Tabii CCE değerini hesaplayabilmek için ağın kategori \n",
    "sayısı kadar çıktıya sahip olması ve bu çıktıların toplamının da 1 olması gerekmektedir. Başka bir deyişle ağın çıktı katmanındaki \n",
    "nöronların aktivasyon fonksiyonları \"softmax\" olmalıdır. Ayrıca CCE çok sınıflı bir entropy hesabı yaptığına göre gerçek \n",
    "değerlerin one-hot encoding biçiminde kodlanmış olması gerekir. (Yani örneğin ileride göreceğimiz gibi K sınıflı bir sınıflandırma \n",
    "problemi için biz ağa çıktı olarak \"one-hot encoding\" kodlanmış K tane y değerini vermeliyiz.) K tane sınıf belirtem bir \n",
    "satırın CCE değeri şöyle hesaplanır (tabii burada K tane \"one-hot encoding\" edilmiş gerçek değer ile M tane softmax çıktı \n",
    "değeri söz konusu olmalıdır):\n",
    "\n",
    "cce = -np.sum(yk * log(yk_hat))\n",
    "\n",
    "Burada yk one-hot encoding yapılmış gerçek değerleri yk_hat ise softmax biçiminde elde edilmiş ağın çıktı katmanındaki \n",
    "değerleri temsil etmektedir.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
