{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebf0026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999983124701\n"
     ]
    }
   ],
   "source": [
    "#Tek Neural Network Ornegi\n",
    "\"\"\"\n",
    "En basit yapay sinir ağı mimarisi tek bir nörondan oluşan mimaridir. Buna \"perceptron\" denilmektedir. Böyle bir model ile\n",
    "\"doğrusal olarak ayrıştırılabilen (linearly separable)\" ikili sınıflandırma problemleri ya da (lojistik olmayan) yalın \n",
    "çoklu regresyon problemleri çözülebilmektedir. Her ne kadar tek bir nöron bile bazı problemleri çözebiliyorsa da problemler \n",
    "karmaşıklaştıkça ağdaki nöron sayılarının ve katmanların artırılması gerekmektedir.  \n",
    "\n",
    "Aşağıda bir nöronun bir sınıfla temsil edilmesine ilişkin bir örnek veriyoruz.\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, w, b):\n",
    "        self.w= w\n",
    "        self.b = b\n",
    "        \n",
    "    def output(self, x, activation):\n",
    "        return activation(np.dot(x, self.w) + self.b)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.e ** x / (1 + np.e ** -x)\n",
    "        \n",
    "w = np.array([1, 2, 3])\n",
    "b = 1.2\n",
    "\n",
    "n = Neuron(w, b)\n",
    "\n",
    "x = np.array([1, 3, 4])\n",
    "result = n.output(x, sigmoid)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1330c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bir yapay sinir ağı modelinde \"katmanlar (layers)\" vardır. Katman aynı düzeydeki nöron grubuna denilmektedir. Yapay sinir ağı \n",
    "katmanları tipik olarak üçe ayırmaktadır:\n",
    "\n",
    "1) Girdi Katmanı (Input Layer)\n",
    "2) Saklı Katmanlar (Hidden Layers)\n",
    "3) Çıktı Katmanı (Output Layer)\n",
    "\n",
    "Girdi katmanı veri kümesindeki satırları temsil eden yani ağa uygulanacak verileri belirten katmandır. Aslında girdi katmanı \n",
    "gerçek anlamda nöronlardan oluşmaz. Ancak anlatımları kolaylaştırmak için bu katmanın da nöronlardan oluştuğu varsayılmaktadır. \n",
    "Başka bir deyişle girdi katmanının tek bir nöron girişi ve tek bir çıktısı vardır. Bunların w değerleri 1'dir. Aktivasyon \n",
    "fonksiyonları f(x) = x biçimindedir. Yani girdi katmanı bir şey yapmaz, girdiyi değiştirmeden çıktıya verir. Girdi katmanındaki \n",
    "nöron sayısı veri kümesindeki sütunların (yani özelliklerin) sayısı kadar olmalıdır. Örneğin 5 tane girdiye (özelliğe) sahip olan \n",
    "bir sinir ağının girdi katmanı şöyle edilebilir:\n",
    "\n",
    "x1 ---> O --->\n",
    "x2 ---> O --->\n",
    "x3 ---> O --->\n",
    "x4 ---> O --->\n",
    "x5 ---> O --->\n",
    "\n",
    "Buradaki O sembolleri girdi katmanındaki nöronları temsil etmektedir. Girdi katmanındaki nöronların 1 tane girdisinin 1 tane de \n",
    "çıktısınn olduğuna dikkat ediniz. Buradaki nöronlar girdiyi değiştirmediğine göre bunların w değerleri 1, b değerleri 0, aktivasyon\n",
    "fonksiyonu da f(x) = x biçiminde olmalıdır. \n",
    "\n",
    "Girdiler saklı katman denilen katmanlardaki nöronlara bağlanırlar. Modelde sıfır tane, bir tane ya da birden fazla saklı katman \n",
    "bulunabilir. Saklı katmanların sayısı ve saklı katmanlardaki nöronların sayısı ve bağlantı biçimleri problemin niteliğine göre \n",
    "değişebilmektedir. Yani saklı katmanlardcaki nöronların girdi katmanıyla aynı sayıda olması gerekmez. Her saklı katmandaki \n",
    "nöron sayıları da aynı olmak zorunda değildir. \n",
    "\n",
    "Çıktı katmanı bizim sonucu alacağımız katmandır. Çıktı katmanındaki nöron sayısı bizim kestirmeye çalıştığımız olgularla ilgilidir. \n",
    "Örneğin biz bir evin fiyatını kestirmeye çalışıyorsak çıktı katmanında tek bir nöron bulunur. Yine örneğin biz ikili sınıflandırma\n",
    "problemi üzerinde çalışıyorsak çıktı katmanı yine tek bir nörondan oluşabilir. Ancak biz evin fiyatının yanı sıra evin sağlamlığını \n",
    "da kestirmek istiyorsak bu durumda çıktı katmanında iki nöron olacaktır. Benzer biçimde çok sınıflı sınıflandırma problemlerinde \n",
    "çıktı katmanında sınıf sayısı kadar nöron bulunur.\n",
    "\n",
    "Bir yapay sinir ağındaki katmanların sayısı belirtilirken bazıları girdi katmanını bu sayıya dahil ederken, bazıları etmemektedir. \n",
    "Bu nedenle katman sayılarını konuşurken yalnızca saklı katmanları belirtmek bu bakımdan iki anlamlılığı giderebilmektedir. \n",
    "Örneğin biz \"modelimizde 5 katman var\" dediğimizde birisi bu 5 katmanın içerisinde girdi katmanı dahil mi diye tereddütte\n",
    "kalabilir. O halde iki anlamlılığı ortadan kaldırmak için \"modelimizde 3 saklı katman var\" gibi bir ifade daha uygun olacaktır.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532c859-7f5d-4021-837a-9ff023662a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bir yapay sinir ağı modelinde katman sayısının artırılması daha iyi bir sonucun elde edileceği anlamına gelmez. Benzer \n",
    "biçimde katmanlardaki nöron sayılarının artırılması da daha iyi bir sonucun elde edileceği anlamına gelmemektedir. Katmanların \n",
    "sayısından ziyade onların işlevleri daha önemli olmaktadır. Ağa gereksiz katman eklemek, katmanlardaki nöronları artırmak \n",
    "tam ters bir biçimde ağın başarısının düşmesine de yol açabilmektedir. Yani gerekmediği halde ağa saklı katman eklemek, \n",
    "katmanlardaki nöron sayısını artırmak bir fayda sağlamamakta tersine kestirim başarısını düşürebilmektedir. Ancak görüntü tanıma \n",
    "gibi özel ve zor problemlerde saklı katman sayılarının artırılması gerekebilmektedir. \n",
    "\n",
    "Pekiyi bir sinir ağı modelinde kaç tane saklı katman olmalıdır? Pratik olarak şunları söyleyebiliriz:\n",
    "\n",
    "- Sıfır tane saklı katmana sahip tek bir nörondan oluşan en basit modele \"perceptron\" dendiğini belirtmiştir. Bu perceptron \n",
    "\"doğrusal olarak ayrıştırılabilen (linearly separable)\" sınıflandırma problemlerini ve yalın doğrusal regresyon problemlerini \n",
    "çözebilmektedir. \n",
    "\n",
    "- Tek saklı katmanlı modeller aslında pek çok sınıflandırma problemini ve (doğrusal olmayan) regresyon problemlerini belli bir \n",
    "yeterlilikte çözebilmektedir. Ancak tek saklı katman yine de bu tarz bazı problemler için yetersiz kalabilmektedir. \n",
    "\n",
    "- İki saklı katman pek çok karmaşık olmayan sınıflandırma problemi için ve regresyon problemi için iyi bir modeldir. Bu nedenle \n",
    "karmaşık olmayan problemler için ilk akla gelecek model iki saklı katmanlı modeldir. \n",
    "\n",
    "- İkiden fazla saklı katmana sahip olan modeller karmaşık ve özel problemleri çözmek için kullanılmaktadır. İki saklı \n",
    "katmandan fazla katmana sahip olan modellere genel olarak \"derin öğrenme ağları (deep learning networks)\" denilmektedir. \n",
    "\n",
    "Yukarıda da belirttiğimiz gibi \"derin öğrenme (deep learning)\" farklı bir yöntemi belirtmemektedir. Derin öğrenme özel ve\n",
    "karmaşık problemleri çözebilmek için ikiden fazla saklı katman içeren sinir ağı modellerini belirtmek için kullanılan bir \n",
    "terimdir.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a3ad7-19a9-4ff6-82fd-7c305ecc6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Yapay sinir ağlarında çalışmak için \"alçak seviyeli\" ve \"yüksek seviyeli\" kütüpaheneler ve framework'ler bulunmaktadır. \n",
    "Aşağı seviyeli üç önemli kütüphane şunlardır: TensorFlow, PyTorch ve Theno. Yüksek seviyeli kütüphane olarak en fazla Keras \n",
    "tercih edilmektedir. Keras eskiden bağımsız bir kütüphaneydi ve kendi içinde TensorFlow, Theno, Microsoft Coginitive Toolkit, \n",
    "PlaidML gibi  kütüphaneleri \"backend\" olarak kullanbiliyordu. Ancak daha sonraları Keras TensorFlow bünyesine katılmıştır. \n",
    "Dolayısıyla artık 2.3 ile birlikte Keras TensorFlow kütüphanesinin bir parçası haline gelmiştir. Bizönce Keras \n",
    "üzerinde ilerleyeceğiz. Ancak sonra diğer aşağı seviyeli kütüphaneleri de gözden geçireceğiz. Keras'la çalışmak için \n",
    "TensorFlow kütüphanesinin kurulması gerekmektedir. Kurulum şöyle yapılabilir:\n",
    "\n",
    "pip install tensorflow\n",
    "\n",
    "TensorFlow çok thread'li ve paralel işlem yapan bir kütüphanedir. Paralel işlemler sırasında grafik kartınının olanaklarını \n",
    "da kullanmaktadır. Eğer Windows sistemlerinde NVidia kartlarını kullanıyorsanız TensorFlow kütüphanesinin performansını \n",
    "artırabilmek için Cuda isimli kütüphaneyi ayrıca yüklemelisiniz. Yükleme aşağıdaki bağlantıdan yapılabilir:\n",
    "\n",
    "https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exe_local\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323bc82-4d1e-4712-8834-6ad4270db2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bir veri kümesini CSV dosyasından okuduktan sonra onu Keras'ın kullanımına hazırlamak için bazı işlemlerin yapılması gerekir. \n",
    "Yapılması gereken ilk işlem veri kümedinin dataset_x ve dataset_y biçiminde iki parçaya ayrılmasıdır. Çünkü ağın eğitilmesi,\n",
    "sırasında girdilerle çıktıların ayrıştırılması gerekmektedir. Burada dataset_x girdileri dataset_y ise kestirilecek çıktıları \n",
    "belirtmektedir. \n",
    "\n",
    "Eğitim bittikten sonra genellikle ağın kestirimine hangi ölçüde güvenileceğini belirleyebilmek için bir test işlemi yapılır. \n",
    "Ağın kestirim başarısı \"test veri kümesi\" denilen bir veri kümesi ile yapılmaktadır. Test veri kümesinin eğitimde kullanılmayan \n",
    "bir veri kümesi biçiminde olması gerekir. (Örneğin bir sınavda yalnızca sınıfta çözülen sorular sorulursa test işleminin başarısı\n",
    "düşebilecektir.) O halde bizim ana veri kümesini \"eğitim veri kümesi\" ve \"test veri kümesi\" biçiminde iki kısma ayırmamız gerekir. \n",
    "Oranlar çeşitli koşullara göre değişebilirse de tipik olarak %80'lik verinin eğitim için %20'lik verinin test için kullanılması \n",
    "tercih edilmektedir. \n",
    "\n",
    "Eğitim ve test veri kümesini manuel olarak ayırabiliriz. Ancak ayırma işleminden önce veri kümesini satırsal bakımdan karıştırmak\n",
    "uygun olur. Çünkü bazı veri kümeleri CSV dosyasına karışık bir biçimde değil yanlı bir biçimde kodlanmış olabilmektedir. Örneğin \n",
    "bazı veri kümeleri bazı alanlara göre sıraya dizilmiş bir biçimde bulunabilmektedir. Biz onun baştaki belli kısmını eğitim, sondaki\n",
    "belli kısmını test veri kümesi olarak kullanırsak eğitim ve test veri kümeleri yanlı hale gelebilmektedir.\n",
    "\n",
    "Biz programlarımızda genellikle bir veri kümesinin tamamı için \"dataset\" ismini, onun girdi kısmı için \"dataset_x\" ismini, \n",
    "çıktı kısmı için \"dataset_y\" ismini kullanacağız. Veri kümesini eğitim ve test olarak ayırdığımızda da isimleri şu biçimde \n",
    "vereceğiz: \"training_dataset_x\", \"training_dataset_y\", \"test_dataset_x\", \"test_dataset_y\".\n",
    "\n",
    "Aşağıda bir kişinin çeşitli biyomedikal bilgilerinden hareketle onun şeker hastası olup olmadığını anlamaya yönelik bir \n",
    "veri kümesinin manuel ayrıştırılması örneği verilmiştir. Veri kümesini aşağıdaki bağlantıdan indirebilirsiniz:\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "Bu kümesinde bazı sütunlar eksik veri içermektedir. Bu eksik verile NaN biçiminde değil 0 biçiminde kodlanmıştır. Biz bu \n",
    "eksik verileri ortaalama değerle doldurabiliriz. Eksik veri içeren sütunlar şunlardır:\n",
    "\n",
    "Glucose\n",
    "BloodPressure\n",
    "SkinThickness\n",
    "Insulin\n",
    "BMI\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d273047-205e-40fa-8405-fc5ab049c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_RATIO = 0.80\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#ilk once imputer yapiyorum\n",
    "si = SimpleImputer(strategy='mean', missing_values=0)\n",
    "df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = si.fit_transform(df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']])\n",
    "\n",
    "#numpya donup shuffle islemi yaptim \n",
    "dataset = df.to_numpy()\n",
    "import numpy as np\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "#datasetlere ayirdim \n",
    "dataset_x = dataset[:, :-1]\n",
    "dataset_y = dataset[:, -1]\n",
    "\n",
    "training_len = int(np.round(len(dataset_x) * TRAINING_RATIO))\n",
    "\n",
    "#4 tane numpy dizisine boldum(training ve test olarak)\n",
    "training_dataset_x = dataset_x[:training_len]\n",
    "test_dataset_x = dataset_x[training_len:]\n",
    "\n",
    "training_dataset_y = dataset_y[:training_len]\n",
    "test_dataset_y = dataset_y[training_len:]\n",
    "\n",
    "#print(training_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3bfcc-c093-446a-94dc-07b4b034d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Veri kümesini eğitim ve test olarak ayırma işlemi için sklearn.model_selection modülündeki train_test_split isimli fonksiyon \n",
    "sıkça kullanılmaktadır. Biz de programlarımızda çoğu zaman bu fonksiyonu kullanacağız. Fonksiyon NumPy dizilerini ya da Pandas \n",
    "DataFrame ve Series nesnelerini ayırabilmektedir. Fonksiyon bizden dataset_x ve dataset_y değerlerini ayrı ayrı ister. test_size \n",
    "ya da train_size parametreleri 0 ile 1 arasında test ya da eğitim verilerinin oranını belirlemek için kullanılmaktadır. \n",
    "train_test_split fonksiyonu bize 4'lü bir liste vermektedir. Listenin elemanları sırasıyla şunlardır: training_dataset_x, \n",
    "test_dataset_x, training_dataset_y, test_dataset_y. Örneğin:\n",
    "\n",
    "training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)\n",
    "\n",
    "Aslında fonksiyonun train_size ve test_size parametreleri float yerine int olarak da girilebilir. Bu parametreler için int\n",
    "türden değer verilirse bu int değer eğitim ve test veri kümesinin sayısını belirtmektedir. Ancak genellikle uygulamacılar \n",
    "bu parametreler için oransal değerler vermeyi tercih etmektedir. \n",
    "\n",
    "train_test_split fonksiyonu veri kümesini bölmeden önce karıştırma işlemini de yapmaktadır. Fonksiyonun shuffle parametresi \n",
    "False yapılırsa fonksiyon karıştırma yapmadan bölme işlemini yapar.\n",
    "\n",
    "training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)\n",
    "\n",
    "Burada fonksiyona dataset_x ve dataset_y girdi olarak verilmiştir. Fonksiyon bunları bölerek dörtlü bir listeye geri dönmüştür.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14ed94-3ea5-4a90-b00a-f8f72f75bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "si = SimpleImputer(strategy='mean', missing_values=0)\n",
    "\n",
    "df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = si.fit_transform(df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']])\n",
    "\n",
    "dataset = df.to_numpy()\n",
    "\n",
    "dataset_x = dataset[:, :-1]\n",
    "dataset_y = dataset[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e5a18e-cfd9-4b0f-9c64-bd07e96c5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_test_split fonksiyonu ile biz doğrudan Pandas DataFrame ve Series nesneleri üzerinde de bölme işlemini yapabiliriz. \n",
    "Bu durumda fonksiyon bize dörtlü listeyi DataFrame ve Series nesneleri biçiminde verecektir. Aşağıda bu biçimde bölmeye \n",
    "bir örnek verilmiştir.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "dataset_x = df.iloc[:, :-1]\n",
    "dataset_y = df.iloc[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)\n",
    "\n",
    "#print(training_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba122ee-291a-49a2-b0d0-b52b92bf67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_test_split fonksiyonu ile biz doğrudan Pandas DataFrame ve Series nesneleri üzerinde de bölme işlemini yapabiliriz. \n",
    "Bu durumda fonksiyon bize dörtlü listeyi DataFrame ve Series nesneleri biçiminde verecektir. Aşağıda bu biçimde bölmeye \n",
    "bir örnek verilmiştir.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "dataset_x = df.iloc[:, :-1]\n",
    "dataset_y = df.iloc[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d8c57-f848-4ce0-8f8c-22cec20b2224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
